{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "# local imports\n",
    "import MNIST_dataloader\n",
    "from scipy import linalg\n",
    "import os\n",
    "import bokeh\n",
    "from ISTA import ISTAI_main\n",
    "PATH = os.path.join(os.getcwd(),'Fast_MRI_Knee')\n",
    "print('Folders in the Fast_MRI_Knee:',os.listdir(PATH)) # os.listdir(PATH)\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "# Load train and test\n",
    "train_loader, test_loader = MNIST_dataloader.create_dataloaders(PATH, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1 \n",
    "## Exercise 2\n",
    "## Learned ISTA (LISTA)\n",
    "\n",
    "In this section, we need to evlove the ISTA into a set of neural netowrk layers. Before to do so, recap of ISTA for sparse decoding problem is following:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    x^{k+1}=\\mathacal{T}_\\lambda(x^k-\\mu A^T(Ax^k-y))\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\01_School\\Q4_5LSL0_MachineLearningForsignalProcessing\\SignalProcessing\\5LSL0_HW\\Assignment4\\Code - for students\\Fast_MRI_Knee\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import Fast_MRI_dataloader \n",
    "batch_size = 64\n",
    "class Fast_MRI(Dataset):\n",
    "    # initialization of the dataset\n",
    "    def __init__(self, split,data_loc):\n",
    "        # save the input parameters\n",
    "        self.split    = split \n",
    "        self.data_loc = data_loc\n",
    "        \n",
    "        # get all the files\n",
    "        self.file_names = glob.glob(f\"{data_loc}//{split}//*.npz\")\n",
    "    \n",
    "    # return the number of examples in this dataset\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)*5\n",
    "    \n",
    "    # create a a method that retrieves a single item form the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx//5]\n",
    "        data = np.load(file_name)\n",
    "        \n",
    "        kspace = data['kspace']\n",
    "        M = data['M']\n",
    "        gt = data['gt']\n",
    "        \n",
    "        # get one of 3 slices\n",
    "        kspace = kspace[idx%5,:,:]\n",
    "        gt = gt[idx%5,:,:]\n",
    "        \n",
    "        return kspace, M, gt\n",
    "\n",
    "PATH = os.path.join(os.getcwd(),'Fast_MRI_Knee')\n",
    "print(PATH)\n",
    "\n",
    "train_loader, test_loader = Fast_MRI_dataloader.create_dataloaders(PATH, batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LISTA Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "                # class Model(nn.Module):\n",
    "                #     def __init__(self):\n",
    "                #         super().__init__()\n",
    "                #         self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "                #         self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "                #     def forward(self, x):\n",
    "                #         x = F.relu(self.conv1(x))\n",
    "                #         return F.relu(self.conv2(x))\n",
    "\n",
    "class smoother(nn.module):\n",
    "    def __init__(self):\n",
    "        # ,mu,shrinkage,K,y\n",
    "        super(smoother,self).__init__()\n",
    "        self.weight = nn.parameter(torch.tensor(1))\n",
    "        self.par_()\n",
    "    def reset_parameters(self):\n",
    "        self.weight.data.uniform_() # Tensor.uniform_, Fills self tensor with numbers sampled from the continuous uniform distribution\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"smooth forwarder\n",
    "        return x + 0.5*(torch.sqrt( torch.square(x + self.weight) + 1) - torch.sqrt( torch.square(x + self.weight) + 1) )\n",
    "        \"\"\"\n",
    "        x = x + 0.5*(torch.sqrt( torch.square(x + self.weight) + 1) - torch.sqrt( torch.square(x + self.weight) + 1) )\n",
    "        return x\n",
    "\n",
    "class LISTA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LISTA,self).__init__()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6baa29261e0939834968439b99fb7dc00c96e7d0a4e424e93f9e6e1808d1076f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
